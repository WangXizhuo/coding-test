{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b572874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d3553e",
   "metadata": {},
   "source": [
    "#### Overall working flow\n",
    "- The simple strategy works as follows:\n",
    "    - **Logistic regression** model is run on several factors.\n",
    "    - A **binary** prediction for a positive or negative return is generated on testing data.\n",
    "    - **Factors** include: \n",
    "        - simple daily return; \n",
    "        - past 20 days volatility;\n",
    "        - 20-day moving average return; \n",
    "        - MACD; \n",
    "        - standardized volume\n",
    "    - Each factor has its lag for 3 times; overall there are **15** factors.\n",
    "    - Check if all the factors are useful by comparing **accuracy scores** on individual models\n",
    "    \n",
    "- Strategy construction and evaluation:\n",
    "    - Building a strategy based on the **scale** of positive return probability\n",
    "    - Check the **evaluation metrics** on the return like average return and sharpe ratio, etc\n",
    "    - Run the three-factor regression on the portfolio return to check significant **alpha**\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5381e5e",
   "metadata": {},
   "source": [
    "#### Step1:  Preprocessing--calculating required factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43ac10ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_window_size = 720\n",
    "rolling_window_size = 45\n",
    "testing_window_size = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88f4634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MACD(x):\n",
    "    k = x['last'].ewm(span=12, adjust=False).mean()\n",
    "    d = x['last'].ewm(span=26, adjust=False).mean()\n",
    "    macd = k - d\n",
    "    # use the signal for 9 days\n",
    "    macd_s = macd.ewm(span=9, adjust=False).mean()\n",
    "    return macd_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f414b69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ticker    0\n",
      "date      0\n",
      "last      0\n",
      "volume    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "# check if there is missing values\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8654e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the factors\n",
    "df[\"return\"] = df.groupby(\"ticker\")[\"last\"].pct_change(1)\n",
    "df[\"volatility\"] = df.groupby(\"ticker\")[\"return\"].rolling(20).std().reset_index(level=0, drop=True)\n",
    "df[\"moving_avg\"] = df.groupby(\"ticker\")[\"return\"].rolling(20).mean().reset_index(level=0, drop=True)\n",
    "df['macd'] = df.groupby(\"ticker\").apply(MACD).reset_index(level=0, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3722aeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the lagged terms of the factors\n",
    "factor_ls = ['return', 'volatility', 'macd', 'volume', 'moving_avg']\n",
    "for lag in range(1, 4):\n",
    "    for factor in factor_ls:\n",
    "        df[f'{factor}_{lag}'] = df.groupby(['ticker'])[factor].shift(lag)\n",
    "# df.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f040cf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove points with na values\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "# print(df.isna().sum(), df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7922368",
   "metadata": {},
   "source": [
    "#### Step2: Strategy model specification\n",
    "- **Attempts made during this step:**\n",
    "    - try all the 15 factor\n",
    "    - try 5 factors of `return`, `volatility`, `volumes`, `macd`, `moving average`.\n",
    "- **Evaluation**\n",
    "    - To compare the accuracy score on the return prediction.\n",
    "- **Conclusion:**\n",
    "    - The accuracy increases with fewer factors.\n",
    "    - Logistic regression is essentially a linear model, the 3 lags of the indicators may have high collinearity, which will negatively affect the fitting result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a987ec3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the available date range to form training and testing dataset\n",
    "dateRange = pd.unique(df.date)\n",
    "# X_ls = df.columns[8:] # all the 15 factors\n",
    "X_ls = ['volume_1','return_1', 'volatility_1', 'macd_1', 'moving_avg_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6df90beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training from date 2013-02-07 to date 2016-01-18 starts.\n",
      "Testing from date 2016-01-19 to date 2016-03-23 finished.\n",
      "Training from date 2013-04-15 to date 2016-03-23 starts.\n",
      "Testing from date 2016-03-24 to date 2016-05-31 finished.\n",
      "Training from date 2013-06-20 to date 2016-05-31 starts.\n",
      "Testing from date 2016-06-01 to date 2016-08-03 finished.\n",
      "Training from date 2013-08-23 to date 2016-08-03 starts.\n",
      "Testing from date 2016-08-04 to date 2016-10-11 finished.\n",
      "Training from date 2013-10-30 to date 2016-10-11 starts.\n",
      "Testing from date 2016-10-12 to date 2016-12-15 finished.\n",
      "Training from date 2014-01-09 to date 2016-12-15 starts.\n",
      "Testing from date 2016-12-16 to date 2017-02-22 finished.\n",
      "Training from date 2014-03-17 to date 2017-02-22 starts.\n",
      "Testing from date 2017-02-23 to date 2017-04-27 finished.\n",
      "Training from date 2014-05-23 to date 2017-04-27 starts.\n",
      "Testing from date 2017-04-28 to date 2017-07-04 finished.\n",
      "Training from date 2014-07-28 to date 2017-07-04 starts.\n",
      "Testing from date 2017-07-05 to date 2017-09-07 finished.\n",
      "Training from date 2014-10-01 to date 2017-09-07 starts.\n",
      "Testing from date 2017-09-08 to date 2017-11-14 finished.\n",
      "Training from date 2014-12-08 to date 2017-11-14 starts.\n",
      "Testing from date 2017-11-15 to date 2018-01-23 finished.\n",
      "Training from date 2015-02-17 to date 2018-01-23 starts.\n",
      "Testing from date 2018-01-24 to date 2018-03-29 finished.\n",
      "Training from date 2015-04-21 to date 2018-03-29 starts.\n",
      "Testing from date 2018-03-30 to date 2018-06-05 finished.\n",
      "Training from date 2015-06-29 to date 2018-06-05 starts.\n",
      "Testing from date 2018-06-06 to date 2018-08-08 finished.\n",
      "Training from date 2015-09-01 to date 2018-08-08 starts.\n",
      "Testing from date 2018-08-09 to date 2018-10-15 finished.\n",
      "Training from date 2015-11-10 to date 2018-10-15 starts.\n",
      "Testing from date 2018-10-16 to date 2018-12-18 finished.\n",
      "Training from date 2016-01-19 to date 2018-12-18 starts.\n",
      "Testing from date 2018-12-19 to date 2019-02-28 finished.\n",
      "Training from date 2016-03-24 to date 2019-02-28 starts.\n",
      "Testing from date 2019-03-01 to date 2019-05-13 finished.\n",
      "Training from date 2016-06-01 to date 2019-05-13 starts.\n",
      "Testing from date 2019-05-14 to date 2019-07-16 finished.\n",
      "Training from date 2016-08-04 to date 2019-07-16 starts.\n",
      "Testing from date 2019-07-17 to date 2019-09-19 finished.\n",
      "Training from date 2016-10-12 to date 2019-09-19 starts.\n",
      "Testing from date 2019-09-20 to date 2019-11-27 finished.\n",
      "Training from date 2016-12-16 to date 2019-11-27 starts.\n",
      "Testing from date 2019-11-28 to date 2020-02-05 finished.\n",
      "Training from date 2017-02-23 to date 2020-02-05 starts.\n",
      "Testing from date 2020-02-06 to date 2020-04-13 finished.\n",
      "Training from date 2017-04-28 to date 2020-04-13 starts.\n",
      "Testing from date 2020-04-14 to date 2020-06-19 finished.\n",
      "Training from date 2017-07-05 to date 2020-06-19 starts.\n",
      "Testing from date 2020-06-22 to date 2020-08-26 finished.\n",
      "Training from date 2017-09-08 to date 2020-08-26 starts.\n",
      "Testing from date 2020-08-27 to date 2020-11-02 finished.\n",
      "Training from date 2017-11-15 to date 2020-11-02 starts.\n",
      "Testing from date 2020-11-04 to date 2021-01-08 finished.\n",
      "Training from date 2018-01-24 to date 2021-01-08 starts.\n",
      "Testing from date 2021-01-12 to date 2021-03-17 finished.\n"
     ]
    }
   ],
   "source": [
    "pred_df_ls = []\n",
    "scaler = StandardScaler()\n",
    "for i in range(training_window_size, len(dateRange)-testing_window_size, rolling_window_size):\n",
    "    trainDate = dateRange[i - training_window_size: i]\n",
    "    testDate = dateRange[i:i + testing_window_size]\n",
    "    X_train, X_test = df.loc[df['date'].isin(trainDate)][X_ls], df.loc[df['date'].isin(testDate)]\n",
    "    # normalizing the volume in each penal    \n",
    "    X_train[['volume_1']] = scaler.fit_transform(X_train[['volume_1']])\n",
    "    X_test[['volume_1']] = scaler.fit_transform(X_test[['volume_1']])\n",
    "\n",
    "    y_train = np.where(df.loc[df['date'].isin(trainDate)]['return'] > 0, 1, 0)\n",
    "    \n",
    "    # model fitting and prediction\n",
    "    model = LogisticRegression(C=1e8, random_state=0).fit(X_train, y_train)\n",
    "    X_test['binaryPred'] = model.predict(X_test[X_ls])\n",
    "    X_test['prediction'] = model.predict_proba(X_test[X_ls])[:, 1]\n",
    "    pred_df_ls.append(X_test[['ticker', 'date', 'return', 'prediction', 'binaryPred']])\n",
    "    \n",
    "    print(f'Training from date {dateRange[i - training_window_size]} to date {dateRange[i-1]} starts.')\n",
    "    print(f'Testing from date {dateRange[i]} to date {dateRange[i+testing_window_size-1]} finished.')\n",
    "    \n",
    "# extract prediction result for evaluation\n",
    "pred_df = pd.concat(pred_df_ls)\n",
    "pred_df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86eef0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5069638473357941"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check accuracy score\n",
    "y_test = np.where(pred_df['return'] > 0, 1, 0)\n",
    "accuracy_score(y_test, pred_df['binaryPred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa8c26d",
   "metadata": {},
   "source": [
    "#### Step3: Building daily portfolio\n",
    "- To check if the strategy is robust, build daily portfolio using all the probabilities\n",
    "    - Every day long stocks with high predicted probability of positive return; short stocks with low predicted probability of positive return\n",
    "    - standardize daily return by dividing the book value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29c583bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolioReturn = {'date':[], 'return':[]}\n",
    "for date in pd.unique(pred_df.date):\n",
    "    dailyPortfolio = pred_df.loc[pred_df['date']==date]\n",
    "    dailyPortfolio['weight'] = dailyPortfolio['prediction'] - dailyPortfolio['prediction'].mean()\n",
    "    \n",
    "    dailyReturn = (dailyPortfolio['weight'] * dailyPortfolio['return']).sum() / dailyPortfolio['weight'].abs().sum()\n",
    "    portfolioReturn['date'].append(date)\n",
    "    portfolioReturn['return'].append(dailyReturn)\n",
    "\n",
    "    # print(f'{date} portfolio finished building.')\n",
    "portfolioReturn = pd.DataFrame(portfolioReturn)\n",
    "# portfolioReturn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea99e3f5",
   "metadata": {},
   "source": [
    "#### Performance evaluation\n",
    "- Basic metrics: average return, standard deviation, sharpe ratio, maximum drawdown\n",
    "- Regression: 3-factor regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22c0bcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_maximum_drawdown(df):\n",
    "        # cumulative_return_pf = np.cumprod(1 + self.rt_sr) - 1\n",
    "        def drawdown(x):\n",
    "            max_retrace = 0\n",
    "            peak = x.iloc[0]\n",
    "            for i in range(len(x)):\n",
    "                if x.iloc[i] > peak:\n",
    "                    peak = x.iloc[i]\n",
    "                dd = (peak - x.iloc[i]) / (1 + peak)\n",
    "                if dd > max_retrace:\n",
    "                    max_retrace = dd\n",
    "            return max_retrace\n",
    "        # cumulative return\n",
    "        cum_rt = (1 + df['return']).cumprod() - 1\n",
    "        return drawdown(cum_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a5a12fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>return</th>\n",
       "      <th>Mkt-RF</th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-19</td>\n",
       "      <td>0.004613</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-20</td>\n",
       "      <td>-0.003452</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>1.88</td>\n",
       "      <td>-1.27</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-21</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>0.007557</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-25</td>\n",
       "      <td>-0.003398</td>\n",
       "      <td>-1.71</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    return  Mkt-RF   SMB   HML   RF\n",
       "0  2016-01-19  0.004613   -0.19 -1.34 -0.06  0.0\n",
       "1  2016-01-20 -0.003452   -0.94  1.88 -1.27  0.0\n",
       "2  2016-01-21  0.000345    0.45 -0.52 -0.02  0.0\n",
       "3  2016-01-22  0.007557    2.08  0.21 -0.20  0.0\n",
       "4  2016-01-25 -0.003398   -1.71 -0.39 -0.99  0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mktFactor = pd.read_csv('F-F_Research_Data_Factors_daily.csv', skiprows=4, skipfooter=1)\n",
    "mktFactor.rename(columns={'Unnamed: 0': 'date'}, inplace=True)\n",
    "mktFactor['date']= mktFactor['date'].astype(str).str[:4] + '-' + \\\n",
    "                   mktFactor['date'].astype(str).str[4:6] + '-' + \\\n",
    "                   mktFactor['date'].astype(str).str[6:]\n",
    "portfolioReturn = portfolioReturn.merge(mktFactor, on='date')\n",
    "portfolioReturn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8645969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average return is 0.0207%.\n",
      "Standard deviation is 0.0042.\n",
      "Sharpe ratio is 0.6290.\n",
      "Maximum Drawdown is 9.1578%.\n"
     ]
    }
   ],
   "source": [
    "avg_return = portfolioReturn['return'].mean()\n",
    "return_std = portfolioReturn['return'].std()\n",
    "sharpe = (portfolioReturn['return'] - portfolioReturn['RF'] / 100).mean() / portfolioReturn['return'].std()\n",
    "maxDrawdown = compute_maximum_drawdown(portfolioReturn)\n",
    "# portfolioReturn.to_csv('portfolioReturn.csv', index=False)\n",
    "sharpe = sharpe * np.sqrt(252)\n",
    "print('Average return is {:.4f}%.'.format(avg_return*100))\n",
    "print('Standard deviation is {:.4f}.'.format(return_std))\n",
    "print('Sharpe ratio is {:.4f}.'.format(sharpe))\n",
    "print('Maximum Drawdown is {:.4f}%.'.format(maxDrawdown*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05f34ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.015\n",
      "Model:                            OLS   Adj. R-squared:                  0.013\n",
      "Method:                 Least Squares   F-statistic:                     6.141\n",
      "Date:                Fri, 20 Jan 2023   Prob (F-statistic):           0.000383\n",
      "Time:                        15:56:31   Log-Likelihood:                 4951.6\n",
      "No. Observations:                1219   AIC:                            -9895.\n",
      "Df Residuals:                    1215   BIC:                            -9875.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0002      0.000      1.365      0.172   -7.15e-05       0.000\n",
      "Mkt-RF      6.816e-05   9.87e-05      0.691      0.490      -0.000       0.000\n",
      "SMB            0.0004      0.000      2.259      0.024    5.75e-05       0.001\n",
      "HML            0.0004      0.000      3.051      0.002       0.000       0.001\n",
      "==============================================================================\n",
      "Omnibus:                      148.229   Durbin-Watson:                   1.948\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              622.295\n",
      "Skew:                           0.507   Prob(JB):                    7.42e-136\n",
      "Kurtosis:                       6.350   Cond. No.                         2.05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "y = portfolioReturn['return'] - portfolioReturn['RF'] / 100\n",
    "X = sm.add_constant(portfolioReturn[['Mkt-RF', 'SMB', 'HML']])\n",
    "threeFactor = sm.OLS(y, X)\n",
    "res = threeFactor.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051c4207",
   "metadata": {},
   "source": [
    "#### Final conclusion\n",
    "- Although the average return and sharpe ratio are not satisfactory, the portfolio has relatively low risk due to low maximum drawdown and standard deviation.\n",
    "- From the 3-factor regression, the portfolio return has high correlation with company size factor and company market value factor. This can be monitored during risk management to avoid market risk.\n",
    "- Finally, the alpha of this portfolio is significant at 10% confidence value. This indicates that more exploration in such direction may be meaningful to create risk-free profits. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
